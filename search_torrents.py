#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ¨æ¼«ç§å­æœç´¢è„šæœ¬
ä»animes.gardenæœç´¢åŠ¨æ¼«ç§å­ï¼Œç”Ÿæˆä¸‹è½½ä»»åŠ¡é˜Ÿåˆ—
"""

import requests
import sys
import json
import os
import datetime
import re
import urllib.parse

# --- è·¯å¾„å®šä¹‰ ---
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
CONFIG_FILE = os.path.join(PROJECT_ROOT, 'config.json')

# --- è¾…åŠ©å‡½æ•° ---
def print_error(msg): print(f"âŒ {msg}", file=sys.stderr)
def print_info(msg): print(f"â„¹ï¸ {msg}")
def print_success(msg): print(f"âœ… {msg}")

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not os.path.exists(CONFIG_FILE):
        print_error(f"é…ç½®æ–‡ä»¶ {CONFIG_FILE} æœªæ‰¾åˆ°!")
        return None
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print_error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None

def load_json_file(filename, default_data):
    """åŠ è½½JSONæ–‡ä»¶"""
    absolute_path = os.path.join(PROJECT_ROOT, filename)
    
    if not os.path.exists(absolute_path):
        print_info(f"æ–‡ä»¶ {absolute_path} æœªæ‰¾åˆ°ï¼Œåˆ›å»ºé»˜è®¤æ–‡ä»¶")
        save_json_file(filename, default_data)
        return default_data
    
    try:
        with open(absolute_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
            
            # æ£€æŸ¥ä¸‹è½½å†å²æ–‡ä»¶æ ¼å¼
            if filename.endswith("download_history.json"):
                if isinstance(content, dict) and "highest_episode_downloaded" in content and "all_downloaded_magnets" in content:
                    return content
                else:
                    print_error(f"{absolute_path} æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                    return {"highest_episode_downloaded": {}, "all_downloaded_magnets": []}
            else:
                return content if content else default_data
    except Exception as e:
        print_error(f"åŠ è½½ {absolute_path} å¤±è´¥: {e}")
        return default_data

def save_json_file(filename, data):
    """ä¿å­˜JSONæ–‡ä»¶"""
    absolute_path = os.path.join(PROJECT_ROOT, filename)
    try:
        os.makedirs(os.path.dirname(absolute_path), exist_ok=True)
        with open(absolute_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print_error(f"ä¿å­˜ {absolute_path} å¤±è´¥: {e}")
        return False

def analyze_magnet_trackers(magnet_url):
    """åˆ†æç£åŠ›é“¾æ¥ä¸­çš„trackerä¿¡æ¯ (æ¥è‡ªæ‚¨çš„ä»£ç )"""
    if not magnet_url:
        return {"tracker_count": 0, "trackers": []}
    
    tracker_count = magnet_url.count('&tr=')
    trackers = []
    
    if '&tr=' in magnet_url:
        parts = magnet_url.split('&tr=')
        for part in parts[1:]: # è·³è¿‡ç¬¬ä¸€éƒ¨åˆ†ï¼ˆhashéƒ¨åˆ†ï¼‰
            # URLè§£ç tracker
            tracker = urllib.parse.unquote(part.split('&')[0])
            trackers.append(tracker)
    
    return {
        "tracker_count": tracker_count,
        "trackers": trackers,
        "has_anime_trackers": any("bangumi.moe" in t or "acgtracker" in t or "ktxp.com" in t for t in trackers)
    }

# --- è¾…åŠ©å‡½æ•°ç»“æŸ ---

# --- æ ¸å¿ƒé€»è¾‘ (æ¥è‡ªæ‚¨çš„ä»£ç , æ— éœ€ä¿®æ”¹) ---

def get_anime_to_scan(config, seasonal_list):
    """
    æ ¹æ®å½“å‰æ—¶é—´è®¡ç®—æ‰«ææ—¶é—´çª—å£ï¼Œå¹¶æ ¹æ®ç•ªå‰§æ’­å‡ºæ—¶é—´å†³å®šæ‰«æå“ªäº›ç•ªå‰§
    """
    global_config = config.get('global_settings', {})
    jst_offset = global_config.get('jst_timezone_offset', 9)
    chinese_weekdays = global_config.get('chinese_weekdays')
    jst_tz = datetime.timezone(datetime.timedelta(hours=jst_offset))

    if not chinese_weekdays or len(chinese_weekdays) != 7:
        print_error("config.json ä¸­ 'chinese_weekdays' é…ç½®é”™è¯¯")
        return {}

    # è·å–JSTå½“å‰æ—¶é—´
    now_jst = datetime.datetime.now(jst_tz)
    print_info(f"å½“å‰JSTæ—¶é—´: {now_jst.strftime('%Y-%m-%d %H:%M:%S %Z%z')}")

    # å®šä¹‰æ‰«ææ—¶é—´çª—å£
    if 0 <= now_jst.hour < 12:
        print_info("æ‰§è¡Œæ—©ä¸Šæ‰«æä»»åŠ¡ï¼ˆç›®æ ‡ï¼šæ˜¨å¤©ä¸­åˆ12ç‚¹è‡³ä»Šæ—©5ç‚¹ï¼‰")
        # å›ºå®šæ—¶é—´çª—å£ï¼šå‰ä¸€å¤©12ç‚¹åˆ°å½“å¤©æ—©ä¸Š5ç‚¹
        scan_end_time = now_jst.replace(hour=5, minute=0, second=0, microsecond=0)
        scan_start_time = (scan_end_time - datetime.timedelta(days=1)).replace(hour=12, minute=0, second=0, microsecond=0)
    elif 12 <= now_jst.hour < 24:
        print_info("æ‰§è¡Œä¸‹åˆè¡¥å……æ‰«æä»»åŠ¡ï¼ˆç›®æ ‡ï¼š3ç‚¹å‰48å°æ—¶ï¼‰")
        # å›ºå®šæ—¶é—´çª—å£ï¼šå‰å¤©ä¸‹åˆ3ç‚¹åˆ°ä»Šå¤©ä¸‹åˆ3ç‚¹
        scan_end_time = now_jst.replace(hour=15, minute=0, second=0, microsecond=0)
        scan_start_time = scan_end_time - datetime.timedelta(hours=48)
    else:
        print_error("æ— æ³•ç¡®å®šæ‰«ææ—¶é—´çª—å£")
        return {}

    print_info(f"æ‰«ææ—¶é—´çª—å£ï¼š{scan_start_time.strftime('%Y-%m-%d %H:%M')} è‡³ {scan_end_time.strftime('%Y-%m-%d %H:%M')}")

    # æ„å»ºç•ªå‰§æ—¶é—´è¡¨
    anime_to_scan = {}
    watchlist = config.get('torrent_searcher', {}).get('search_config', {})
    schedule = {}
    
    for item in seasonal_list:
        schedule[item['primary_title']] = item
        for name in item.get('all_cn_names', []):
            if name != item['primary_title']:
                schedule[name] = item

    print_info(f"å¼€å§‹æ£€æŸ¥ {len(watchlist)} éƒ¨å…³æ³¨çš„ç•ªå‰§")

    for title, search_config in watchlist.items():
        anime_info = schedule.get(title)
        if not anime_info:
            print_info(f"è·³è¿‡ï¼šç•ªå‰§ '{title}' åœ¨æ”¾é€è¡¨ä¸­æœªæ‰¾åˆ°")
            continue
            
        air_weekday_cn = anime_info.get('weekday')
        air_time_str = anime_info.get('begin_time')
        
        if not air_weekday_cn or not air_time_str:
            print_info(f"è·³è¿‡ï¼šç•ªå‰§ '{title}' ç¼ºå°‘æ’­å‡ºæ—¶é—´ä¿¡æ¯")
            continue

        try:
            air_weekday_index = chinese_weekdays.index(air_weekday_cn)
            air_hour, air_minute = map(int, air_time_str.split(':'))
            air_time = datetime.time(hour=air_hour, minute=air_minute, tzinfo=jst_tz)
            is_in_window = False

            # æ£€æŸ¥æ’­å‡ºæ—¶é—´æ˜¯å¦åœ¨æ‰«æçª—å£å†…
            check_dates = [
                scan_end_time.date() - datetime.timedelta(days=2),
                scan_end_time.date() - datetime.timedelta(days=1),
                scan_end_time.date()
            ]
            
            for check_date in check_dates:
                check_dt = datetime.datetime.combine(check_date, air_time)
                if check_dt.weekday() == air_weekday_index and scan_start_time <= check_dt < scan_end_time:
                    is_in_window = True
                    break

            if is_in_window:
                print_success(f"åŠ å…¥æ‰«æé˜Ÿåˆ—ï¼š{title}ï¼ˆ{air_weekday_cn} {air_time_str}ï¼‰")
                anime_to_scan[title] = search_config
            else:
                print_info(f"è·³è¿‡ï¼š{title}ï¼ˆ{air_weekday_cn} {air_time_str}ï¼‰ä¸åœ¨æ—¶é—´çª—å£å†…")
                
        except Exception as e:
            print_error(f"å¤„ç†ç•ªå‰§ {title} æ—¶å‡ºé”™: {e}")

    return anime_to_scan


def parse_episode_number(title):
    """ä»æ ‡é¢˜ä¸­è§£æé›†æ•°"""
    match = re.search(
        r'\[(\d{1,3}(?:\.\d{1,2})?)(?:v\d)?\]|'
        r'[\s\.\-_\[](\d{1,3})[\s\.\-_\]]|'
        r'ç¬¬(\d{1,3})[è¯è©±é›†]|'
        r'(\d{1,3})\s*END',
        title,
        re.IGNORECASE
    )
    if match:
        for group in match.groups():
            if group is not None:
                try:
                    num = float(group)
                    if 0 <= num < 1000:
                        return num
                except ValueError:
                    continue
    return None

def search_and_select_episode(search_title, config, api_url, history_data):
    """æœç´¢å¹¶é€‰æ‹©æœ€æ–°é›†æ•°"""
    search_keys = config.get('search_keys', [])
    print(f"\n{'='*50}")
    print_info(f"æœç´¢ï¼š{search_title}")
    print_info(f"å…³é”®è¯ï¼š{search_keys}")
    print(f"{'='*50}")

    params = {'page': 1, 'pageSize': 30, 'search': search_keys}
    highest_downloaded_ep = history_data.get('highest_episode_downloaded', {}).get(search_title, 0.0)
    downloaded_magnets_set = set(history_data.get('all_downloaded_magnets', []))
    
    print_info(f"å†å²æœ€é«˜é›†æ•°ï¼š{highest_downloaded_ep}")

    try:
        prepared_request = requests.Request('GET', api_url, params=params).prepare()
        print_info(f"è¯·æ±‚URLï¼š{prepared_request.url}")

        with requests.Session() as session:
            response = session.send(prepared_request, timeout=20)
        response.raise_for_status()

        data = response.json()
        resources = data.get('resources', [])

        if not resources:
            print_info("APIæœªè¿”å›åŒ¹é…èµ„æº")
            return None

        # è¿‡æ»¤æ–°èµ„æº
        new_resources = []
        for r in resources:
            magnet = r.get('magnet')
            if magnet and magnet not in downloaded_magnets_set:
                tracker_count = magnet.count('&tr=')
                print_info(f"æ–°èµ„æºï¼š{r.get('title', 'æœªçŸ¥')} (åŒ…å« {tracker_count} ä¸ªtracker)")
                new_resources.append(r)

        if not new_resources:
            print_info("æ‰€æœ‰èµ„æºéƒ½å·²ä¸‹è½½è¿‡")
            return None

        # æ‰¾åˆ°æœ€æ–°é›†æ•°
        latest_new_episode_resource = None
        max_new_episode_num = -1.0
        
        print_info(f"æ‰¾åˆ° {len(new_resources)} ä¸ªæ–°èµ„æºï¼Œå¼€å§‹ç­›é€‰")

        for r in new_resources:
            title = r.get('title', '')
            episode_num = parse_episode_number(title)
            if episode_num is None:
                print_info(f"è·³è¿‡ï¼šæ— æ³•è§£æé›†æ•° - {title}")
                continue
            if episode_num > max_new_episode_num:
                max_new_episode_num = episode_num
                latest_new_episode_resource = r

        if latest_new_episode_resource:
            magnet_info = analyze_magnet_trackers(latest_new_episode_resource.get('magnet'))
            print_info(f"æ–°èµ„æºæœ€é«˜é›†æ•°ï¼š{max_new_episode_num}")
            print_info(f"æ ‡é¢˜ï¼š{latest_new_episode_resource.get('title')}")
            print_info(f"Trackeræ•°é‡ï¼š{magnet_info['tracker_count']}")
            print_info(f"åŠ¨æ¼«ä¸“ç”¨Trackerï¼š{'æ˜¯' if magnet_info['has_anime_trackers'] else 'å¦'}")
            
            if max_new_episode_num > highest_downloaded_ep:
                print_success(f"è¯¥é›†æ•° ({max_new_episode_num}) é«˜äºå†å²è®°å½• ({highest_downloaded_ep})ï¼Œæ ‡è®°ä¸‹è½½")
                if magnet_info['tracker_count'] > 0:
                    print_success(f"ç£åŠ›é“¾æ¥è´¨é‡è‰¯å¥½ï¼šåŒ…å« {magnet_info['tracker_count']} ä¸ªtracker")
                return latest_new_episode_resource, max_new_episode_num
            else:
                print_info(f"è¯¥é›†æ•° ({max_new_episode_num}) ä¸é«˜äºå†å²è®°å½• ({highest_downloaded_ep})ï¼Œè·³è¿‡")
                return None
        else:
            print_info("æ‰¾åˆ°æ–°èµ„æºä½†æ— æ³•è§£æé›†æ•°")
            return None

    except Exception as e:
        print_error(f"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

# --- (å…³é”®ä¿®æ”¹) main å‡½æ•° ---

def main():
    if sys.platform == "win32":
        sys.stdout.reconfigure(encoding='utf-8')

    print("ğŸ” åŠ¨æ¼«ç§å­æœç´¢è„šæœ¬")
    print("=" * 50)

    # 1. åŠ è½½é…ç½®
    config = load_config()
    if not config:
        return
    global_config = config.get('global_settings', {})
    script_config = config.get('torrent_searcher', {})

    # 2. åŠ è½½æ”¾é€è¡¨
    # (ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°, ä¼ å…¥ config.json ä¸­çš„ç›¸å¯¹è·¯å¾„)
    seasonal_file = config.get('seasonal_fetcher', {}).get('output_file')
    if not seasonal_file:
        print_error("config.json ä¸­ 'seasonal_fetcher.output_file' æœªé…ç½®")
        return
        
    seasonal_list = load_json_file(seasonal_file, [])
    if not seasonal_list:
        print_error(f"{seasonal_file} ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ get_seasonal_anime.py")
        return

    # 3. åŠ è½½ä¸‹è½½å†å² (ä»…ç”¨äºè¯»å–)
    # (ä½¿ç”¨æ–°çš„è¾…åŠ©å‡½æ•°, ä¼ å…¥ config.json ä¸­çš„ç›¸å¯¹è·¯å¾„)
    history_file = global_config.get('download_history_file')
    if not history_file:
        print_error("config.json ä¸­ 'global_settings.download_history_file' æœªé…ç½®")
        return
        
    history_data = load_json_file(history_file, {"highest_episode_downloaded": {}, "all_downloaded_magnets": []})

    # 4. è·å–ä»Šå¤©è¯¥æ‰«æçš„ç•ªå‰§ (ä¸å˜)
    anime_to_scan = get_anime_to_scan(config, seasonal_list)

    if not anime_to_scan:
        print_info("å½“å‰æ—¶é—´çª—å£å†…æ²¡æœ‰éœ€è¦æ‰«æçš„ç•ªå‰§")
        return

    # 5. æ‰§è¡Œæœç´¢
    print_info(f"å¼€å§‹æ‰«æ {len(anime_to_scan)} éƒ¨ç•ªå‰§")
    api_url = global_config.get('torrent_api_url')
    # (ä¿®æ”¹) output_file æ˜¯ search_results.json
    output_file = script_config.get('output_file')
    
    # (ä¿®æ”¹) å‡†å¤‡ä¸€ä¸ªåˆ—è¡¨æ¥è£…å®Œæ•´çš„â€œä»»åŠ¡å¯¹è±¡â€
    new_tasks_for_queue = []

    for title, conf in anime_to_scan.items():
        # search_and_select_episode å‡½æ•°æœ¬èº«ä¸éœ€è¦ä¿®æ”¹
        result = search_and_select_episode(title, conf, api_url, history_data)
        
        if result:
            episode_resource, episode_num = result
            
            # (æ–°å¢) æ„å»ºä¸€ä¸ªå®Œæ•´çš„ä»»åŠ¡å¯¹è±¡, ä¾› download_bt.py ä½¿ç”¨
            task_object = {
                "anime_title": title, # è¿½ç•ªåˆ—è¡¨ä¸­çš„æ ‡å‡†åç§° (ç”¨äºæ›´æ–°å†å²)
                "episode": episode_num, # è§£æå‡ºçš„é›†æ•° (ç”¨äºæ›´æ–°å†å²)
                "title": episode_resource.get('title'), # èµ„æºåŸå§‹æ ‡é¢˜
                "magnet": episode_resource.get('magnet') # ç£åŠ›é“¾æ¥
            }
            new_tasks_for_queue.append(task_object)

    # 6. (ä¿®æ”¹) ä¿å­˜ç»“æœ -> å®‰å…¨åœ°è¿½åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—
    if not output_file:
        print_info(f"æœªé…ç½® 'output_file', ä»…æ‰“å°ç»“æœã€‚")
    elif new_tasks_for_queue:
        print_info(f"æ­£åœ¨å°† {len(new_tasks_for_queue)} ä¸ªæ–°ä»»åŠ¡æ·»åŠ åˆ° {output_file}...")
        
        # 6a. (æ–°å¢) è¯»å–ç°æœ‰çš„ä»»åŠ¡é˜Ÿåˆ— (search_results.json)
        existing_tasks = load_json_file(output_file, [])
        
        # 6b. (æ–°å¢) åˆå¹¶å¹¶å»é‡ (åŸºäºç£åŠ›é“¾æ¥)
        existing_magnets = {task.get('magnet') for task in existing_tasks}
        added_count = 0
        for new_task in new_tasks_for_queue:
            if new_task.get('magnet') not in existing_magnets:
                existing_tasks.append(new_task)
                existing_magnets.add(new_task.get('magnet'))
                added_count += 1
            else:
                print_info(f"ä»»åŠ¡ '{new_task.get('title')}' å·²å­˜åœ¨äºé˜Ÿåˆ—ä¸­, è·³è¿‡æ·»åŠ ã€‚")
        
        # 6c. (ä¿®æ”¹) ä¿å­˜åˆå¹¶åçš„å®Œæ•´é˜Ÿåˆ—
        if save_json_file(output_file, existing_tasks):
            print_success(f"æˆåŠŸå°† {added_count} ä¸ªæ–°ä»»åŠ¡è¿½åŠ åˆ° {output_file}")
        else:
            print_error(f"!!! ä¿å­˜ä»»åŠ¡é˜Ÿåˆ— {output_file} å¤±è´¥ !!!")
    
    # 7. (å·²åˆ é™¤) æ­¤è„šæœ¬ä¸å†è´Ÿè´£æ›´æ–° download_history.json
    
    print_info(f"\n--- æ‰«æå®Œæ¯• ---")
    print_success(f"å…±æ‰¾åˆ° {len(new_tasks_for_queue)} ä¸ªç¬¦åˆæ›´æ–°æ¡ä»¶çš„å‰§é›†, å·²æ·»åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—ã€‚")

if __name__ == "__main__":
    main()